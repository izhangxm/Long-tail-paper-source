\begin{abstract}
The long-tailed problem has been a long-standing research topic in research of Chinese historical text recognition tasks.
Specifically, the long-tailed problem refers to that the tail classes usually have poor performance due to the extreme imbalance of samples.
To address this problem, we propose to emphasize modeling low-level features, which are reused in head classes and tail classes alike, to alleviate the class-wise imbalance problem.
As an implementation, we propose a novel spindle network that improves low-level feature extraction capabilities by reallocating parameters from deeper layers to shallow ones.
The proposed approach effectively alleviates the long-tail problem in historical text recognition by improving the performance of some tail classes due to the component similarities between characters.
We also noticed that improving low-level feature extraction capabilities also improves the accuracy of the head class by improving thereby 
%Specifically, we reshape the number of head parameters of the feature extraction network into a spindle structure. For feature extraction networks, while the number of channels in shallow layers increases, the number of channels in deep layers decreases. In order to keep the number of parameters unchanged to the maximum extent, the total number of channels after deformation remains the same as before deformation. 
%Compared with the mainstream model structure, the spindle network can significantly improve the feature extraction capability, thereby improving the recognition accuracy of tail category characters. 
Further experiments demonstrated the effectiveness of the spindle network. Extensive experiments on three challenging Chinese ancient book datasets (TKH, MTH1000, and MTH1200) verify that our method achieves state-of-the-art performances. Channels of high level are reduced while channels of low level are increased.
\end{abstract}